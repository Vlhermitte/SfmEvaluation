\chapter{Conclusion}\label{chap:conclusion}
This thesis set out to answer two overarching questions:

\begin{enumerate}
    \item How do recent learning-based SfM pipelines (AceZero, FlowMap, VGGSfM) compare with classical feature-based methods (COLMAP, GLOMAP) in terms of pose accuracy, scalability and downstream novel-view quality ?
    \item What are the practical trade-offs in memory, run-time and completeness when deploying these pipelines on real-world mobile captures ?
\end{enumerate}

To address them, we introduced a unified evaluation protocol that couples rigorous camera-pose metrics (relative/absolute pose errors, AUC) with a task-oriented assessment based on Gaussian-splat novel-view synthesis.  
Benchmarks span controlled indoor scenes (ETH3D), large-scale urban traverses (LaMAR) and high-resolution radiance-field datasets (MipNeRF360, Tanks And Temples).

\subsubsection{Key findings}
\paragraph{GLOMAP excels in accuracy and completeness balance.}
It tops every relative-pose metric on ETH3D and registers $>99\,\%$ of frames, while its median translation error stays below \SI{2}{cm}.  
Rare but catastrophic scale flips (e.g.\ \SI{3.9}{km} outlier in \texttt{courtyard}) slightly inflate mean errors.

\paragraph{COLMAP remains a robust baseline.}
Although it misses more frames than GLOMAP, it delivers the lowest mean translation error (\SI{8.8}{cm}) and the sharpest Gaussian-splat renders in confined interiors.

\paragraph{VGGSfM offers mid-tier accuracy but poor scalability.}
Memory usage rises beyond \SI{30}{GB} for ETH3D scenes and the sliding-window optimiser stalls on long LaMAR sequences.

\paragraph{AceZero is promising yet brittle.}
It shines on circular trajectories (closed-loop MipNeRF360 scenes) but fails during outdoor-to-indoor transitions and registers few images when confidence drops below the $1\,000$ threshold.

\paragraph{FlowMap trails the field.}
Full-batch optical-flow warping drives linear VRAM growth and collapses on wide-baseline imagery, yielding PSNR as low as \SI{13}{dB} on MipNeRF360 .


\subsubsection{Contributions}
\begin{itemize}
    \item A comparative study of five state-of-the-art SfM pipelines across diverse scenes.
    \item An open-source evaluation suite that unifies camera-pose metrics and Gaussian-splat novel-view synthesis.
\end{itemize}

\subsubsection{Limitations}
\begin{enumerate}
    \item \textbf{Dataset scale.} Experiments stopped at 1500 images; claims about $>10\,000$ image performance (especially for AceZero) remain unverified.
    \item \textbf{Single-intrinsic assumption.} To accommodate AceZero, only mono-device sequences were used; heterogeneous-sensor scenarios were left out.
    \item \textbf{Hardware ceiling.} Two methods exceeded the 32 GB VRAM budget, meaning their ETH3D scores stem from down-scaled or truncated runs.
\end{enumerate}

\subsubsection{Directions for future work}
% \begin{itemize}
%     \item \textbf{Learned local features in classical pipelines.} Plugging SuperPoint into COLMAP/GLOMAP via HLoc could boost robustness to blur and lighting changes with minimal engineering effort.
%     \item \textbf{Heterogeneous-sensor evaluation.} Extending the benchmark to mixed-intrinsic datasets would test generalisation beyond the current mono-intrinsic setting.
%     \item \textbf{Full LaMAR dataset.} Rather than treating each LaMAR sessions individually, an evaluation on the full scale dataset would provide a more comprehensive understanding of the methods' performance.
% \end{itemize}
Replacing handcrafted SIFT with learned features (SuperPoint \cite{detone18superpoint} with SuperGlue \cite{sarlin2020superglue} or LighGlue \cite{lindenberger2023lightglue}) inside COLMAP and GLOMAP is a low-hanging fruit: Hloc already provides drop-in wrappers.
% For FlowMap, implementing mini-batch flow warping should unlock much larger sequences.  
% AceZero would benefit from a distortion-aware camera model, and the ability to handle multiple camera intrinsics.
Finally, we suggest extending the benchmark to mixed-intrinsic and large datasets (e.g. Co3D \cite{reizenstein21co3d}, IMC \cite{Jin2020}, ScanNet \cite{dai2017scannet}) to test the generalisation of our findings.

\subsubsection{Closing remarks}
Classical feature-based pipelines, when carefully engineered, still set the bar for metric accuracy and downstream view synthesis.  
Among the methods we evaluated, \textbf{GLOMAP emerges as the sole alternative mature enough to displace COLMAP}: it combines comparable geometric precision with higher registration completeness and markedly faster runtimes.  
Other learning-based approaches remain promising research directions, but they have yet to match this robustness-scalability sweet spot.  
Bridging classical geometry with learned priors, rather than treating them as mutually exclusive paradigms, therefore appears the most fruitful path toward the next generation of structure-from-motion systems.